
# Part 1 — EquiformerV2 / OCP(OC20) 학습·배포 README의 독립 개념 설명

## 1) GitHub Repository(저장소)

GitHub 저장소(repository)는 코드, 모델 설정(config), 문서, 데이터 준비 스크립트, 학습/평가 실행 스크립트 등 프로젝트를 재현하기 위한 자산을 한 곳에 모아 관리하는 단위다. `atomicarchitects/equiformer_v2` 같은 형태는 “소유자/프로젝트명”을 뜻하며, 해당 저장소가 공개(public)인지, 라이선스가 무엇인지, 어떤 브랜치와 커밋 히스토리를 갖는지 등이 함께 관리된다.

연구 코드 저장소에서 중요한 점은 “재현성(reproducibility)”이다. 같은 데이터셋과 같은 설정으로 학습했을 때 동일하거나 유사한 성능이 나와야 하고, 특정 시점의 코드를 가리키는 커밋 해시로 정확히 버전 고정이 가능해야 한다. README는 사용자가 환경 설정부터 데이터 다운로드, 학습 실행, 체크포인트 사용까지 흐름을 따라갈 수 있도록 안내하는 핵심 문서다.

---

## 2) Commit Hash(커밋 해시) 및 “커밋 해시 업데이트”

커밋 해시는 Git에서 특정 스냅샷(변경 기록)의 고유 식별자다. 논문/코드에서 “어느 시점의 구현을 사용했는지”를 정확히 지정하려면 커밋 해시를 인용하는 방식이 가장 확실하다. 특히 결과 재현이 중요한 ML/계산과학에서는 “모델 체크포인트가 어느 커밋에서 만들어졌는지” 같은 provenance(출처 추적)가 가치가 크다.

README에 “`git checkout …`로 더 이상 커밋 해시를 찾을 수 없어서 업데이트했다” 같은 문구가 나오는 경우는, 히스토리 정리(예: force push, history rewrite)나 저장소 구조 변경으로 예전 해시가 더 이상 접근 불가능해진 상황을 의미할 수 있다. 이런 경우 사용자 입장에서는 “동일 결과 재현”이 어려워질 수 있으므로, 체크포인트와 설정 파일을 함께 제공하거나 OCP 본가 저장소에 통합된 경로를 안내하는 것이 안정적인 해결책이 된다.

---

## 3) README(프로젝트 사용 설명서)

README는 프로젝트의 “가장 중요한 단일 문서”로, 무엇을 제공하는지(모델/코드/데이터), 어떤 작업을 지원하는지(학습/평가/추론), 어떤 전제 조건이 필요한지(환경/데이터 경로)를 요약한다. 특히 OCP 계열처럼 데이터셋 규모가 크고 학습 설정이 복잡한 프로젝트는 README를 따라가며 셋업하는 것이 사실상 표준이다.

연구 코드 README에서 핵심은 “사용자 여정”을 끊김 없이 만드는 것이다. 예를 들어 데이터 다운로드 → 폴더 구조 준비 → 학습 스크립트 실행 → 체크포인트 다운로드/로드 → 평가 실행의 단계가 명확해야 하고, 흔한 오류(예: import error, 경로 문제, split 파일 누락)의 해결 가이드가 포함되면 재현성이 크게 좋아진다.

---

## 4) MIT License(MIT 라이선스)

MIT 라이선스는 매우 관대한(permissive) 오픈소스 라이선스로, 소프트웨어를 사용·복사·수정·배포·상업적 이용까지 폭넓게 허용한다. 일반적으로 요구되는 의무는 “저작권 고지와 라이선스 전문을 유지”하는 정도이며, GPL처럼 파생물 공개를 강제하지 않는다.

연구 코드에서 MIT 라이선스가 갖는 의미는 “산업/학계에서 사용 장벽이 낮다”는 점이다. 기업이나 연구기관이 내부 프로젝트에 적용해도 법적 제약이 비교적 적고, 파생 모델이나 파생 코드를 만들더라도 배포 방식에 자유도가 높다. 다만 데이터셋(OCP/OC20)은 별도의 라이선스/약관이 있을 수 있으므로 코드 라이선스와 데이터 라이선스를 혼동하면 안 된다.

---

## 5) Equiformer(Equivariant Graph Attention Transformer)

Equiformer는 3D 원자 시스템에서 중요한 “회전/병진 변환에 대한 등변성(equivariance)”을 만족하도록 설계된 그래프 기반 트랜스포머 계열 모델이다. 등변성은 입력 구조를 회전시키면 출력(예: 힘 벡터)이 같은 방식으로 회전해야 한다는 물리적 요구사항을 반영하며, 특히 힘 예측이나 구조 이완(relaxation)에서는 필수에 가깝다.

일반적인 Transformer가 텍스트/이미지에서 주로 “불변성(invariance)” 또는 약한 형태의 공간 처리만 한다면, Equiformer는 3D 공간에서의 군 대칭(SO(3) 등)에 맞춰 feature를 표현하고 attention 연산을 구성한다. 이 덕분에 더 적은 데이터로도 물리적으로 일관된 예측을 할 수 있고, 촉매 표면–흡착 시스템처럼 복잡한 3D 상호작용에서도 일반화가 좋아질 수 있다.

---

## 6) EquiformerV2(Improved Equivariant Transformer)

EquiformerV2는 Equiformer의 개선 버전으로, 더 큰 모델/더 높은 표현 차수로 확장(scaling)할 때 성능과 학습 안정성을 개선하는 방향의 업데이트를 담는다. README에서 “Scaling to Higher-Degree Representations”를 강조하는 이유는, SO(3) 표현에서 degree(차수)가 높아질수록 더 풍부한 각도/방향 정보를 담을 수 있지만 계산량과 불안정성이 함께 커지기 때문이다.

v2의 메시지는 단순히 “더 큰 모델”이 아니라, 고차 표현을 실용적으로 쓰기 위한 설계(효율, 안정성, 정확도)를 개선했다는 점에 있다. OCP의 S2EF 같은 작업은 힘 예측 정확도가 전체 성능을 좌우하므로, 이러한 아키텍처적 개선이 실제 벤치마크 점수(Force MAE 등)로 연결되는지가 핵심 성과로 제시된다.

---

## 7) Equivariant(등변성) vs Invariant(불변성)

등변성(equivariance)은 입력에 어떤 변환을 가했을 때 출력이 그 변환에 “같은 방식으로” 반응하는 성질이다. 예를 들어 원자 구조를 회전시키면 힘 벡터도 동일하게 회전해야 한다. 이는 물리적으로 자연스러운 제약이며, 모델이 이를 구조적으로 내장하면 데이터 효율과 일반화가 개선되는 경우가 많다.

불변성(invariance)은 입력을 변환해도 출력이 변하지 않는 성질이다. 예를 들어 총에너지(스칼라)는 구조를 회전해도 값이 같아야 한다. 원자계 ML에서는 에너지는 불변, 힘은 등변이라는 조합이 대표적이다. 따라서 좋은 원자계 모델은 에너지 불변성과 힘 등변성을 함께 만족하도록 설계되며, Equiformer 계열이 바로 이 요구사항을 겨냥한다.

---

## 8) Higher-Degree Representations(고차 표현, 높은 차수의 SO(3) 표현)

3D 등변 모델은 흔히 SO(3) 군의 표현(representation)을 사용해 각도 정보를 담는다. 여기서 degree(차수)가 높아질수록 더 복잡한 방향성 패턴을 표현할 수 있어, 원자 주변의 비등방성(방향 의존성) 상호작용을 더 정확히 모델링할 가능성이 커진다.

하지만 고차 표현은 비용이 급격히 증가하고 학습도 불안정해질 수 있다. 그래서 “고차 표현으로 스케일링”은 단순히 표현력을 키우는 문제가 아니라, 연산 효율/메모리/학습 안정성을 함께 해결해야 가능한 목표다. EquiformerV2가 이 부분을 전면에 내세우는 것은, OCP 같은 대규모 작업에서 성능 향상이 곧바로 실용적 이득으로 이어지기 때문이다.

---

## 9) Open Catalyst Project(OCP)

Open Catalyst Project(OCP)는 촉매 표면(slab)과 흡착종(adsorbate) 시스템에서 에너지·힘을 예측하는 ML 모델을 발전시키기 위한 커뮤니티 프로젝트이자 코드/데이터/벤치마크 생태계다. 특히 OCP는 “구조 이완(Structure-to-Energy & Force)” 같은 실제 촉매 계산 워크플로의 핵심 단계를 ML로 가속하는 것을 목표로 한다.

OCP의 실용성은 단순 예측이 아니라 “이완(relaxation) 품질”에 있다. 촉매 연구에서는 안정한 흡착구조를 찾는 게 중요하고, 이는 힘 예측이 정확해야 가능한 작업이다. OCP는 모델 아키텍처(EquiformerV2 등)뿐 아니라 데이터 다운로드, 학습/평가 스크립트, 표준 메트릭을 제공해 커뮤니티가 같은 기준으로 비교하도록 만든다.

---

## 10) OC20(Open Catalyst 2020) Dataset

OC20은 OCP에서 제공한 대규모 촉매 데이터셋으로, 다양한 촉매 표면과 흡착종 조합에 대한 DFT 계산 결과(에너지/힘)를 포함한다. 이 데이터셋의 목적은 “새로운 표면-흡착 시스템에서도 잘 일반화되는 모델”을 만들 수 있도록 폭넓은 화학공간을 제공하는 것이다.

OC20은 특히 구조 이완과 연결된 작업(S2EF)에서 대표적 표준으로 자리 잡았다. 논문/코드에서 OC20을 언급하는 것은 “우리 모델이 촉매-흡착 문제에서 검증된 벤치마크를 통과했다”는 의미를 갖는다. 다만 데이터셋 규모가 커서 다운로드/저장/전처리 방식이 프로젝트의 중요한 실무 요소가 된다.

---

## 11) S2EF(Structure-to-Energy-and-Forces) 태스크

S2EF는 구조(원자 위치/원자종)를 입력으로 받아 에너지와 힘을 예측하는 작업이다. 촉매 표면에서 흡착구조를 이완하려면 힘이 정확해야 하므로, S2EF는 단순 예측 과제가 아니라 “구조 최적화 워크플로의 핵심 엔진” 성격을 가진다.

S2EF에서 중요한 건 에너지 MAE보다도 **Force MAE**가 더 직접적이라는 점이다. 힘 오차가 크면 이완 과정에서 잘못된 방향으로 원자가 이동해 잘못된 국소 최소점에 빠지거나 발산할 수 있다. 따라서 README에서 “force trainer”나 “relaxation training”을 강조하는 것은, 실제 촉매 계산에서 쓸 수 있는 모델을 목표로 한다는 신호다.

---

## 12) Dataset Split(데이터 분할)과 “2M / All+MD”

데이터 분할(split)은 학습(train)·검증(val)·테스트(test) 또는 데이터 규모에 따른 서브셋을 나누는 방식이다. OC20에서 “2M” 같은 표현은 특정 규모(예: 2 million 샘플 수준)의 서브셋을 의미하는 경우가 많고, 더 큰 분할은 더 넓은 화학공간을 포함해 모델의 일반화를 높일 수 있다.

“All+MD” 같은 분할은 “전체 데이터(All)”에 더해 MD(분자동역학)에서 추출된 비평형 구조나 추가 트래젝토리를 포함하는 설정을 뜻한다. 표면–흡착 시스템에서 이완 경로 중간의 비평형 구조까지 학습에 포함하면, 모델이 단순 평형 구조 주변에서만 잘하는 게 아니라 이완 과정 전체를 더 안정적으로 따라가도록 훈련될 수 있다.

---

## 13) MD Data(분자동역학 데이터) 추가 학습의 의미

MD 데이터는 평형점 주변의 작은 진동뿐 아니라, 이완/열적 요동/비평형 상태에서 나타나는 다양한 구조를 포함할 수 있다. 촉매 표면에서 흡착종이 이동하거나 표면 재구성이 일어나는 과정은 비평형 구조가 많기 때문에, 이런 데이터는 모델의 안정성과 범용성을 높이는 데 도움이 된다.

“All+MD”처럼 MD 기반 샘플을 넣는 전략은 “실제 이완 궤적에서 만나게 될 구조 분포”를 더 잘 커버하기 위한 것이다. 특히 구조 이완 모델은 중간 단계에서 힘 방향을 잘못 잡으면 이후 궤적 전체가 무너질 수 있으므로, MD 데이터는 단순 성능 향상 이상의 “실행 안정성”을 제공하는 경우가 있다.

---

## 14) DeNS(Denoising Non-Equilibrium Structures)

DeNS는 “비평형 구조를 잡음 제거(denoising)하는 자기지도학습(self-supervised learning)” 아이디어를 3D 원자 시스템에 적용한 보조 과제(auxiliary task)로 설명된다. 텍스트에서 BERT가 문장 일부를 가리고 맞히는 방식으로 표현을 학습하듯, 원자 구조에서도 일부를 교란/노이즈 처리한 뒤 원래 구조/힘/에너지와 일관된 표현을 학습시키는 접근으로 볼 수 있다.

이 보조 과제의 핵심 장점은 라벨(정확한 에너지/힘)만으로 학습할 때보다 더 풍부한 구조적 표현을 얻을 수 있다는 점이다. 특히 이완 과정에서 등장하는 비평형 구조는 “데이터 분포 바깥”이 되기 쉬운데, DeNS 같은 방식은 비평형 구조를 다루는 표현력을 강화해 에너지/힘 예측 성능을 올리는 방향으로 작동할 수 있다.

---

## 15) Self-Supervised Learning(자기지도 학습)과 “BERT-like”

자기지도 학습은 정답 레이블이 없는 데이터에서도, 데이터 자체에서 학습 신호를 만들어 representation(표현)을 학습하는 방법이다. BERT는 문장 일부를 가리고(mask) 맞히는 식으로 언어의 구조를 학습하는 대표 사례다. 원자계에서도 비슷하게 “교란된 구조를 원래로 복원”하거나, “불완전한 정보로 일관된 물리량을 맞히는” 보조 과제를 만들 수 있다.

원자계에서 자기지도 학습이 유용한 이유는, DFT 에너지/힘 계산이 비싸서 라벨 데이터가 항상 충분하지 않기 때문이다. 보조 과제로 학습된 표현은 다운스트림 태스크(에너지/힘 예측)에 전이되어, 같은 라벨 수로도 더 좋은 성능을 내거나, OOD 상황에서 더 안정적으로 동작하도록 돕는 역할을 한다.

---

## 16) Integrated into OCP(“OCP 저장소에 통합”)

어떤 모델이 “OCP 저장소에 통합”되었다는 말은, 해당 모델이 단독 연구 코드로만 존재하는 게 아니라 OCP의 표준 학습/평가 파이프라인 안에서 바로 사용할 수 있는 형태로 포함되었다는 뜻이다. 이는 사용자 입장에서 설치/실행이 쉬워지고, 동일한 벤치마크 설정으로 비교가 용이해진다는 실무적 장점을 준다.

또한 커뮤니티 관점에서 통합은 “모델이 표준 생태계에서 검증·유지보수될 가능성이 높다”는 의미가 있다. 독립 저장소는 시간이 지나면 의존성 충돌이나 경로 변경 등으로 사용이 어려워질 수 있는데, OCP 메인에 들어가면 상대적으로 장기적으로 살아남는 편이다.

---

## 17) Open Catalyst Demo(데모)

데모는 모델이 “연구 결과로만 존재”하는 게 아니라 실제로 입력을 주고 구조 이완이나 예측을 돌려볼 수 있는 예시를 제공하는 형태다. OCP 데모는 일반적으로 표면–흡착 구조를 넣으면 모델이 에너지/힘을 예측하고, 이를 이용해 구조를 relax하는 과정을 보여주는 식으로 구성된다.

데모가 중요한 이유는 사용자가 “이 모델이 내 시스템에도 쓸만한가?”를 빠르게 판단할 수 있게 해주기 때문이다. 특히 촉매 분야에서는 표면/흡착종 조합이 다양해 일반화가 어렵기 때문에, 데모는 단순 홍보가 아니라 실사용 검증의 출발점 역할을 한다.

---

## 18) Environment Setup(환경 설정)

환경 설정은 파이썬 패키지 의존성(PyTorch, PyG, e3nn 등), CUDA 버전, 컴파일/런타임 요구사항 등을 맞추는 과정이다. 원자계 등변 모델은 GPU 메모리와 커널 최적화에 민감하고, PyTorch 및 관련 확장 라이브러리의 버전 호환성이 깨지면 실행 자체가 안 되는 경우가 많다.

README에서 환경 설정 링크를 별도로 두는 것은, 이 프로젝트가 단순 `pip install`로 끝나는 수준이 아니라는 의미이기도 하다. 따라서 실제 운영에서는 `conda` 또는 `uv/pip-tools`로 lockfile을 고정하고, CUDA 및 PyTorch 버전을 명확히 맞추는 게 재현성에 매우 중요하다.

---

## 19) Dataset Download(데이터 다운로드) 스크립트

`python scripts/download_data.py --task s2ef --split "2M" ...` 같은 명령은 OCP가 제공하는 표준 다운로드 스크립트를 통해 원하는 태스크/분할 데이터를 받는 방법이다. 태스크(s2ef), split(2M), worker 수(num-workers), 참조 에너지(ref-energy) 옵션 등을 조합해 대용량 데이터를 병렬로 내려받는다.

대규모 데이터셋에서는 다운로드 자체도 실패/중단이 빈번할 수 있어, 스크립트가 재시도나 분할 다운로드를 지원하는 경우가 많다. 실무적으로는 스토리지 경로, 심볼릭 링크, 데이터 캐시 위치를 명확히 해두지 않으면 학습 스크립트가 데이터를 못 찾는 문제가 자주 발생한다.

---

## 20) `--num-workers`(다운로드 워커 수)

`--num-workers 8` 같은 옵션은 데이터를 병렬로 다운로드/전처리하기 위해 프로세스(또는 스레드)를 몇 개 쓸지 지정한다. 워커 수를 늘리면 다운로드 시간이 줄어들 수 있지만, 네트워크/디스크 I/O가 병목이면 효과가 제한적이며 오히려 서버에 부담을 줄 수도 있다.

학습 프로젝트에서 워커 수는 단순 성능 튜닝이 아니라 “안정성”과도 연결된다. 너무 큰 워커 수를 잡으면 서버 정책에 의해 연결이 차단되거나, 파일 핸들 제한에 걸릴 수 있다. 따라서 팀/기관 인프라 환경에 맞춰 적절한 병렬 수를 선택하는 것이 필요하다.

---

## 21) `--ref-energy`(참조 에너지 옵션)

OCP 데이터셋에서는 어떤 경우 흡착 에너지를 계산할 때 “참조 에너지(reference energy)”를 함께 제공하거나, 에너지 기준을 통일하기 위해 보정값을 포함하는 옵션이 존재할 수 있다. `--ref-energy`는 다운로드 시 이러한 참조 관련 파일/필드를 함께 받도록 하는 플래그로 이해할 수 있다.

참조 에너지는 특히 표면–흡착 시스템에서 에너지 정의가 여러 방식으로 가능하기 때문에 중요하다. 예를 들어 절대 에너지(총에너지)로만 비교할지, 기체상 분자의 참조를 빼서 흡착 에너지로 볼지에 따라 해석이 달라진다. 같은 벤치마크를 공정하게 비교하려면 데이터가 제공하는 기준을 정확히 따르는 것이 필수다.

---

## 22) `val_id` Split과 Split File(분할 파일)

`val_id` 같은 표현은 검증셋을 특정 기준으로 분리한 서브셋을 가리키는 경우가 많다. 예를 들어 “ID(in-distribution) 검증”은 학습 분포와 유사한 검증 데이터를 의미하고, 반대로 OOD(out-of-distribution) 검증은 더 어려운 일반화 성능을 점검하는 용도로 쓰인다.

README에서 `val_id` 학습을 위해 별도의 “data split file”을 다운로드하라고 하는 이유는, 분할 방식이 고정되어야 실험 비교가 가능하기 때문이다. 같은 데이터셋이라도 split이 바뀌면 점수 비교가 무의미해질 수 있으므로, 분할 파일은 벤치마크의 일부로 취급되는 핵심 구성요소다.

---

## 23) `ln -s`(심볼릭 링크)로 데이터 경로 연결

`ln -s ~/ocp/data/s2ef s2ef` 같은 명령은 심볼릭 링크(symbolic link)를 만들어, 실제 데이터가 있는 경로를 프로젝트가 기대하는 폴더 구조 아래에 “연결”하는 방법이다. 대규모 데이터셋을 여러 프로젝트가 공유하는 환경에서는 데이터를 중복 저장하지 않고 링크로 재사용하는 것이 일반적이다.

심볼릭 링크는 편리하지만, 경로가 꼬이면 “데이터를 찾지 못하는” 문제가 자주 생긴다. 특히 상대경로/절대경로 혼동, 권한 문제, 컨테이너 환경에서 호스트 경로가 보이지 않는 문제 등이 발생할 수 있다. 따라서 README의 폴더 구조(`datasets/oc20/...`)를 정확히 맞추는 것이 실행 안정성에 매우 중요하다.

---

## 24) Multi-node Training(멀티 노드 학습)

멀티 노드 학습은 여러 대의 서버(노드)에서 GPU를 묶어 분산 학습하는 방식이다. README에서 “2 nodes × 8 GPUs”처럼 표기하는 것은, 한 노드당 8개의 GPU를 사용하며 총 16 GPU로 학습한다는 의미다. OC20처럼 데이터 규모가 크고 모델이 무거우면 멀티 노드가 사실상 필수인 경우가 많다.

멀티 노드 학습은 단순히 GPU 개수를 늘리는 것 이상의 복잡성이 있다. 노드 간 통신(NCCL), 네트워크 대역폭(InfiniBand 여부), 분산 런처(torchrun 등), 체크포인트 저장 방식이 모두 영향을 준다. 따라서 제공된 `.sh` 스크립트는 보통 해당 클러스터 환경에 맞춘 실행 예시이며, 사용자는 자신의 스케줄러(Slurm 등) 설정에 맞춰 수정이 필요하다.

---

## 25) “각 노드 8 GPU” 같은 하드웨어 전제

한 노드에 GPU 8개가 있다는 전제는 일반적으로 DGX 계열 또는 HPC 노드 구성을 상정한다. 이런 전제는 단순 스펙 안내가 아니라, 해당 모델 학습이 요구하는 자원 규모를 암시한다. 예를 들어 “16 노드 × 8 GPU”가 등장하면, 이는 대규모 분산 학습을 통해서만 해당 설정(예: 153M 모델, All+MD)을 현실적으로 학습할 수 있다는 뜻이다.

실무적으로는 자원이 부족한 환경에서는 “작은 모델(예: 31M)”이나 “작은 split(2M)”로 시작해 파이프라인을 검증한 뒤 확장하는 전략이 필요하다. 또한 mixed precision, gradient checkpointing, batch size scaling 같은 기법을 함께 써서 단일 노드에서도 최대한 재현 가능한 설정을 만드는 것이 연구 생산성을 높인다.

---

## 26) Shell Script(`scripts/train/... .sh`) 기반 학습 실행

README에서 학습 실행을 `sh scripts/train/... .sh`로 제공하는 방식은, 복잡한 분산 학습 인자를 사용자에게 직접 치게 하지 않고 스크립트에 고정해 제공하려는 목적이 있다. 여기에는 모델 아키텍처 파라미터(N, L, M 같은 표기), 데이터 split, GPU 수, 노드 수, 로깅/체크포인트 경로 등이 포함된다.

하지만 스크립트는 “예시”일 뿐, 사용자의 환경에 맞춰 수정이 필요한 경우가 많다. 예를 들어 Slurm 환경이면 `srun`/`sbatch` 래퍼가 필요하고, 단일 서버면 multi-nodes 스크립트 대신 `g@8` 같은 단일 노드 스크립트를 써야 한다. 따라서 스크립트를 통해 실행 흐름을 이해하고, 핵심 하이퍼파라미터와 경로만 조정하는 식으로 접근하는 것이 좋다.

---

## 27) Import Error(가져오기 오류)와 `ocpmodels/common/utils.py` 수정

“가져오기 오류(import error)”는 파이썬에서 모듈 경로나 API가 바뀌었는데 코드가 그에 맞춰 업데이트되지 않았을 때 흔히 발생한다. 특히 OCP 본가 저장소는 활발히 업데이트되므로, 특정 시점의 EquiformerV2 코드가 기대하는 OCP 내부 함수가 다른 버전에서는 사라졌을 수 있다.

README에서 특정 파일(`ocp/ocpmodels/common/utils.py`)의 수정되지 않은 부분을 원인으로 지목하는 것은 “버전 호환성 이슈”의 전형적인 패턴이다. 이런 문제를 줄이려면 (1) OCP 저장소의 특정 커밋에 의존하도록 고정하거나, (2) requirements/환경을 강하게 핀(pin)하거나, (3) 통합된 최신 OCP 구현을 우선 사용해야 한다.

---

## 28) “훈련기(trainer)”와 Force Trainer

트레이너(trainer)는 학습 루프(데이터 로딩, forward, loss 계산, backprop, 로깅, 체크포인트 저장)를 캡슐화한 코드 구조를 말한다. OC20 S2EF에서는 힘 예측이 중요하므로, force loss를 안정적으로 다루는 “force trainer”가 따로 존재하거나, 에너지와 힘을 함께 최적화하는 다중 목적 loss 구성이 들어가는 경우가 많다.

힘 학습은 단순 회귀보다 민감하다. 좌표 미분에 해당하는 값이라 노이즈에 취약하고, 잘못된 스케일링이나 loss weight 설정은 모델을 불안정하게 만들 수 있다. 따라서 트레이너가 어떤 loss 구성(에너지 vs 힘 비중), 어떤 스케줄(러닝레이트/워밍업), 어떤 정규화(힘 단위/원자 수 정규화)를 사용하는지 이해하는 것이 재현과 성능 튜닝의 핵심이다.

---

## 29) Relaxation(구조 이완) 학습/평가/실행

구조 이완(relaxation)은 초기 구조에서 출발해 힘을 따라 원자를 이동시키며 에너지를 낮춰 안정 구조를 찾는 과정이다. ML 모델이 힘을 정확히 예측하면, DFT 대신 ML로 이완을 수행하여 계산 비용을 크게 줄일 수 있다. OCP가 S2EF를 강조하는 이유도 이 때문이다.

README에서 “relaxation training, evaluation and running”을 위한 코드가 따로 있다는 말은, 단순히 에너지/힘을 한 번 예측하는 것이 아니라, 그 예측을 반복적으로 사용해 최적화 루프를 돌린다는 뜻이다. 이 과정에서 작은 힘 오차가 누적될 수 있으므로, 단일 스텝 MAE뿐 아니라 “최종 이완 구조의 품질”이 중요한 평가 기준이 된다.

---

## 30) Configuration File(설정 파일)과 실험 재현성

설정 파일(config)은 모델 아키텍처(레이어 수, 히든 차원, cutoff), 학습 하이퍼파라미터(배치, LR), 데이터 경로, 분산 학습 설정 등을 담는다. README에서 “checkpoint | config”를 같이 제공하는 이유는, 체크포인트만으로는 학습 설정을 복원하기 어렵기 때문이다.

실험 재현성에서는 “코드+체크포인트+config”의 삼위일체가 중요하다. 체크포인트가 같은 모델 파라미터를 갖고 있어도, 전처리나 데이터 split이 달라지면 성능 비교가 의미 없어질 수 있다. 따라서 config를 함께 제공하고, 가능하면 config가 사용한 커밋/환경 정보를 포함하도록 만드는 게 좋은 연구 습관이다.

---

## 31) Checkpoint(체크포인트)

체크포인트는 학습된 모델 파라미터(가중치)와 때로는 옵티마이저 상태, 스케줄러 상태까지 저장한 파일이다. README에서 여러 데이터 분할(2M, All+MD)과 모델 크기(31M, 153M)에 대해 체크포인트를 제공하는 것은, 사용자가 “학습을 다시 하지 않고” 평가/추론을 재현할 수 있게 하기 위함이다.

체크포인트를 사용할 때 중요한 것은 “무엇을 예측하려는가”와 “도메인이 맞는가”다. 예를 들어 OC20 기반 체크포인트는 촉매 표면–흡착 시스템에 최적화되어 있을 가능성이 높고, 벌크 결정이나 MOF 같은 다공성 유기-무기 혼합계에는 도메인 갭이 있을 수 있다. 따라서 체크포인트 사용 시에는 설정 파일과 함께 모델이 의도한 태스크/데이터 범위를 확인해야 한다.

---

## 32) Force MAE(meV/Å)와 Energy MAE(meV) 메트릭

MAE(Mean Absolute Error)는 예측과 정답의 절대 오차 평균이다. Force MAE가 `meV/Å` 단위로 주어지는 이유는 힘이 에너지의 거리 미분이므로 에너지/길이 단위를 갖기 때문이다. S2EF에서 Force MAE는 구조 이완 성능과 직접적으로 연결되며, 힘 오차가 낮을수록 이완이 안정적으로 수렴할 가능성이 크다.

Energy MAE는 스칼라 에너지 예측 오차이며 단위는 보통 `meV`로 표시된다. 다만 촉매 시스템에서는 절대 에너지보다 “에너지 차이(흡착 에너지, 반응 에너지)”가 중요할 때가 많고, 에너지 MAE가 낮아도 힘이 나쁘면 이완 품질이 떨어질 수 있다. 그래서 OCP에서는 힘 메트릭을 별도로 강조하며, 두 메트릭을 함께 보고 모델을 평가한다.

---

## 33) Model Size(31M, 153M 등 파라미터 규모)

31M, 153M은 모델 파라미터 개수(약 3,100만 / 1억5,300만)를 뜻하는 표기다. 파라미터 수가 늘면 표현력이 커져 성능이 좋아질 수 있지만, 학습 비용(시간, GPU 메모리, 통신)이 크게 증가한다. 그래서 README가 모델 크기에 따른 학습 리소스(노드 수)를 함께 제시하는 것이다.

대형 모델은 또한 “데이터와 최적화”의 영향을 더 크게 받는다. 충분한 데이터(All+MD 같은 큰 분할)와 적절한 학습 스케줄이 없으면 대형 모델이 오히려 불안정하거나 과적합/과소적합을 겪을 수 있다. 따라서 사용자는 자신의 자원과 목적에 맞춰 작은 체크포인트로 시작해 파이프라인을 검증한 뒤 확장하는 전략이 현실적이다.

---

## 34) Citation(BibTeX 인용)과 연구 소프트웨어 인용 관행

README의 BibTeX 항목은 해당 코드/모델을 논문에서 인용할 때 사용하도록 제공하는 서지 정보다. 연구 소프트웨어는 논문과 별개로도 학술 기여로 인정받기 때문에, 코드를 사용해 결과를 만들었다면 해당 논문을 인용하는 것이 학계 관행이다.

특히 OCP처럼 커뮤니티 벤치마크 기반 연구는 “데이터셋 논문(OC20) + 모델 논문(Equiformer/EquiformerV2) + 기반 기법(eSCN 등)”을 함께 인용하는 경우가 많다. 이는 단순 예의가 아니라, 결과 비교의 전제가 되는 방법/데이터를 명확히 해 독자가 실험 조건을 추적 가능하게 만드는 역할도 한다.

---

## 35) ICLR / ICML / OpenReview / arXiv

ICLR, ICML은 ML 분야 대표 국제 학회이고, OpenReview는 ICLR 등에서 사용하는 공개 리뷰/논문 공개 플랫폼이다. README에서 “논문 | 오픈리뷰 | 포스터”를 함께 링크하는 것은, 모델 설명과 실험 세부사항을 사용자가 쉽게 확인하도록 하기 위함이다.

arXiv는 프리프린트 서버로, 학회 출판 전/후로 논문을 공개할 수 있다. 깃헙 저장소에서 arXiv 링크를 제공하는 건 구현과 논문을 연결해주는 중요한 단서다. 사용자는 논문에서 모델의 설계 철학과 한계를 파악하고, 코드에서는 실제 구현/학습 레시피를 따라가며 재현할 수 있다.

---

## 36) eSCN(Reducing SO(3) Convolutions to SO(2))

eSCN은 SO(3) 등변 컨볼루션을 SO(2)로 축소해 효율을 높이는 아이디어를 다룬 등변 GNN 계열 연구다. 3D 회전 대칭을 다루는 연산은 계산 비용이 크기 때문에, 이를 더 단순한 형태로 바꾸면서도 핵심 등변성을 유지하는 접근은 대규모 학습에서 큰 실용적 가치를 가진다.

README에서 eSCN을 “기반/참조”로 인용하는 것은, Equiformer 계열이 등변 표현과 연산 최적화의 누적된 연구 흐름 위에 서 있음을 드러낸다. 즉, 단일 모델의 성능 향상은 종종 (1) 더 좋은 표현, (2) 더 효율적인 등변 연산, (3) 더 안정적인 학습 레시피가 결합된 결과로 나오며, eSCN은 그 중 효율/연산 측면의 주요 전개로 볼 수 있다.

---

## 37) SO(3)와 SO(2)(회전 군) — 3D 등변 모델의 수학적 배경

SO(3)는 3차원 공간에서의 회전(rotation) 군(group)이다. 원자계는 좌표계 선택에 따라 회전될 수 있는데, 물리량은 그 회전에 대해 일관되게 변해야 한다. 그래서 3D 등변 모델은 SO(3) 대칭을 반영하도록 설계되는 경우가 많다.

SO(2)는 2차원 회전 군이며, 특정 표현/연산을 SO(2)로 줄이는 것은 계산 효율을 높이는 데 도움이 될 수 있다. 다만 축소 과정에서 정보 손실이나 근사 오차가 생길 수 있으므로, 모델 설계에서는 정확도–효율 트레이드오프를 정교하게 다룬다. eSCN 같은 작업은 이런 트레이드오프를 더 나은 지점으로 옮기는 데 기여한다.

---

## 38) Dependencies: PyTorch / PyG / e3nn / timm / ocp

PyTorch는 딥러닝 모델을 구현/학습하기 위한 대표 프레임워크다. PyG(PyTorch Geometric)는 그래프 신경망을 위한 라이브러리로, 원자계를 그래프로 표현(원자=노드, 결합/근접=엣지)하는 데 유용하다. Equiformer 계열은 그래프 기반 구조 위에 등변성을 결합하는 경우가 많아 PyG가 기반이 된다.

e3nn은 3D 등변 신경망을 구현하기 위한 핵심 라이브러리로, SO(3) 표현/텐서 곱/구면조화함수 등 등변 연산에 필요한 도구를 제공한다. timm은 비전 모델 유틸리티/모듈 모음으로 트랜스포머 구성요소를 가져오는 데 쓰일 수 있다. ocp는 OCP 표준 코드베이스로, 데이터/학습 파이프라인/평가를 제공해 모델이 커뮤니티 표준에 올라타게 해준다.

---

## 39) “파일 구조(nets / scripts / oc20 / trainer / configs)”라는 모듈 분리

`nets`는 보통 모델 아키텍처 정의가 들어가는 곳이다. 등변 트랜스포머의 레이어, 표현 차수, attention 블록 같은 핵심 네트워크 코드가 여기에 모인다. `scripts`는 학습/평가 실행을 자동화하는 셸 스크립트나 파이썬 스크립트를 담는다. 이런 분리는 “모델 정의”와 “실행 레시피”를 분리해 유지보수성을 높인다.

`oc20/` 아래에는 OC20 태스크(S2EF 등)에 특화된 트레이너, 데이터 로더, 평가 코드가 들어간다. `configs`는 각 실험 설정을 파일로 저장해 실험 추적을 가능케 한다. 이런 구조는 연구 프로젝트에서 매우 흔하며, 사용자는 모델을 바꾸고 싶으면 `nets`, 학습 세팅을 바꾸고 싶으면 `configs`/`scripts`를 주로 건드리게 된다.

---

## 40) “Inference/Invocation(소환)” — 학습된 모델을 불러 쓰는 과정

README의 “소환(Invocation)”은 체크포인트를 불러 모델을 구성하고, 입력 구조에 대해 에너지/힘을 예측하는 사용 단계를 뜻한다. 이는 단순히 모델을 로드하는 것뿐 아니라, 데이터 전처리(원자종 인코딩, neighbor 계산), cutoff 적용, 배치 구성 등 추론 파이프라인 전체를 포함한다.

촉매 워크플로에서 추론은 종종 “이완 루프” 안에 들어간다. 즉 한 번 예측하고 끝나는 게 아니라, 힘으로 원자를 이동시키고 다시 예측하는 과정을 반복한다. 따라서 inference 단계에서의 속도/안정성은 모델 실용성의 핵심이며, 체크포인트–config–코드 버전의 일치가 깨지면 예측이 비정상적이거나 성능이 크게 떨어질 수 있다.

---

## 41) “Issues / Pull Requests / Actions” (협업·품질관리 메커니즘)

Issues는 버그 리포트, 기능 요청, 질문 등을 기록하는 공간이다. 연구 코드에서 issues가 잘 관리되면 사용자들이 겪는 환경 문제나 실행 오류가 누적되어 해결책이 문서화된다. Pull Request(PR)는 코드 변경 제안이며, 리뷰를 통해 품질을 유지하고 기여를 받아들이는 방식이다.

Actions는 CI(continuous integration)나 자동 테스트/빌드 파이프라인을 구성하는 기능이다. ML 연구 코드에서 CI가 완벽하게 작동하긴 어렵지만, 최소한 import 테스트, 간단한 유닛 테스트, 코드 스타일 체크를 자동화하면 시간이 지나도 코드가 깨지는 것을 줄일 수 있다. 특히 OCP처럼 의존성이 자주 변하는 생태계에서는 이런 자동화가 실사용성을 크게 좌우한다.

---

## 42) “공공/공개(public)” 저장소와 재현성의 사회적 의미

공개 저장소는 누구나 코드를 내려받아 실행할 수 있게 한다. 이는 과학적 검증 가능성, 재현성, 커뮤니티 확산에 직접 기여한다. 특히 데이터셋/벤치마크 기반 연구는 많은 그룹이 같은 기준에서 비교해야 의미가 있으므로, 공개는 연구의 영향력을 높이는 핵심 요소다.

다만 공개 저장소도 “실행 가능한 상태”를 유지하는 것은 별개의 일이다. 시간이 지나 의존성이 바뀌면 코드는 쉽게 깨지며, 문서와 버전 고정이 부족하면 사용자는 재현에 실패한다. 그래서 체크포인트와 config 제공, 데이터 다운로드 안내, 흔한 에러 대응이 README에 포함되는 것이 매우 중요하다.

---

## 43) “속도–정확도 상충(Trade-off)”과 벤치마크 결과(OC22 등)

속도–정확도 trade-off는 MLIP/등변 모델에서 늘 존재한다. 더 복잡한 표현(높은 degree), 더 큰 모델(153M)은 보통 정확도를 올리지만 비용을 증가시킨다. 반대로 작은 모델은 빠르지만 성능이 제한될 수 있다. README에서 “속도-정확도 수치”를 추가했다는 변경 로그는 사용자가 실사용 맥락에서 모델을 선택할 수 있게 정보를 제공하는 것이다.

OC22는 OC20의 후속/확장 벤치마크 계열로 이해할 수 있으며(README 맥락상), 이런 벤치마크 결과는 모델의 최신 성능을 비교하는 근거가 된다. 다만 벤치마크 점수는 특정 split/설정에 의존하므로, 동일한 프로토콜(데이터 split, ref-energy, 평가 코드 버전)에서 나온 수치인지 확인하는 것이 중요하다.
