<!-- 파일명: 2025-12-13.idea.reaction-dino.md -->

# 2025-12-13.idea.reaction-dino.md

아래는 **Reaction DINO 프로젝트를 “논문까지 가는 수준”으로 진행하기 위한 준비사항 + 엔드투엔드 파이프라인(데이터→학습→평가→리포팅→재현성)**을 한 번에 쓸 수 있게 정리한 실행 계획서다.
(기본 가정: **Teacher는 특권정보(제품/atom-mapping/Δ변환)**를 보고, **Student는 reactants-only 또는 “제한된 입력”만** 본다.)

---

## 0. Reaction DINO가 풀고자 하는 것

Reaction DINO의 핵심은 **“반응물만 보고도(또는 제한된 정보만 보고도) 반응 변환 패턴을 내재화한 representation을 학습”**하는 것이다.

### Teacher가 보는 특권 정보(Privileged info) 예시
- Products
- Atom-mapping
- CGR(Condensed Graph of Reaction)
- (가능하면) 조건(촉매/용매/온도)

### Student가 보는 정보 예시
- Reactants-only
- mapping 없음
- 조건 없음

### 목표
- 라벨 없이(혹은 약한 라벨만으로) 학습한 embedding이
  `reaction classification / retrieval / yield / forward / retro` 등에서 **강력한 backbone**이 되는 것.

> CGR는 “반응을 단일 그래프로 합성”하는 대표 반응 표현이라 **Teacher 쪽 특권정보로 매우 적합**하다.

---

## 1. 프로젝트 전체 준비사항 체크리스트

### 1.1 연구 설계(논문 임팩트가 나는 포인트를 미리 고정)

#### 반드시 고정해야 할 4가지
1. **Student 입력 제약**:
   `reactants-only / (reactants+reagents) / 조건 포함 여부`
2. **Teacher 특권 정보**:
   `product 포함 여부, atom-mapping 필요 여부, CGR 사용 여부`
3. **DINO 헤드 설계**:
   `prototype 기반(online clustering) + centering/temperature + EMA teacher`
4. **평가 축**:
   “스크리닝/실험 절감”으로 연결되는 다운스트림(분류/검색/수율/전이)

#### 논문에서 강한 주장 포맷(권장)
- “Reactants-only로도 reaction transformation prototype을 복원하는 self-distilled representation”
- “(특권정보: mapping/CGR/product)를 제거해도 성능 유지 → 산업 적용성”

### 1.2 데이터 전략(벤치마크의 함정까지 포함)
- **USPTO-50K**: 고전 벤치마크(수동 큐레이션/자주 사용)
- **USPTO-MIT / USPTO-FULL**: 대규모 특허 추출 데이터(사전학습용에 적합)
- 최근 USPTO 계열 벤치마크의 **스플릿/전처리/누수(중복)** 문제를 다루는 비판적 분석도 있으니, 논문에서 데이터 준비의 정당화를 꼭 넣는 게 좋다.

> 실전 권장:
> `사전학습 = USPTO-MIT/FULL`
> `파인튜닝/평가 = USPTO-50K + 추가 태스크(수율/분류/검색)`
> 로 “전이성(transfer)”을 강조.

### 1.3 베이스라인(최소 3개는 고정)
- **rxnfp (Reaction BERT 계열 fingerprint)**: 반응 임베딩/검색 대표 baseline
- **DRFP**: 학습 없이도 강한 reaction fingerprint baseline
- **CGR 기반 learned representation**(또는 CGR feature + ML): “변환 그래프” 대표 축
- (옵션) **반응 지식 그래프 기반 사전학습(ReaKE류)**도 관련 축으로 언급 가능

### 1.4 컴퓨팅/스택 준비
- **필수 라이브러리**:
  `RDKit(전처리/표준화), PyTorch(+PyG), tokenizers(SMILES용이면), pandas/pyarrow`
- **실험 관리**:
  `Hydra(설정), W&B/MLflow(추적), DVC/git-lfs(데이터 버전)`
- **리소스**:
  - 사전학습(USPTO-MIT급)은 **1~4 GPU**면 현실적(배치/시퀀스 길이/그래프 크기에 따라)
  - atom-mapping/전처리 단계는 **CPU 병렬/캐싱**이 핵심

---

## 2. Reaction DINO 파이프라인(End-to-End)

아래는 “최소 구현(MVP) → 논문급(Full)”로 자연스럽게 확장되는 구조다.

### 2.1 데이터 수집 & 정규화

#### (A) 원천 데이터
1. **사전학습 데이터**: USPTO-MIT 또는 USPTO-FULL (대규모)
2. **평가 데이터**: USPTO-50K + (가능하면) 추가 다운스트림(수율/분류)

#### (B) 필수 정제(누수/중복 방지 포함)
- **SMILES 표준화**: salt 제거/중성화/tautomer 규칙(가능하면 일관 룰)
- **반응 중복 제거**: canonical reaction SMILES 기준 dedup
- **원자 수/무기물/이상 반응 필터**: 너무 긴/깨진 케이스 제거
- **스플릿**
  - 최소: random split
  - 논문 설득력: `Tanimoto / scaffold / 시간 기반 split` 중 하나 추가(일반화 주장 강화)

---

### 2.2 반응 표현(Teacher/Student 입력 정의)

#### 옵션 1: Teacher = CGR, Student = Reactants-only graph
- **Teacher 입력**: CGR 그래프(reactant+product를 overlay, bond 변화가 feature로 들어감)
- **Student 입력**: reactants 분자 그래프들을 **set**으로 처리(순서 불변)
- **장점**: “변환(Δ)”을 Teacher가 직접 보므로 distillation이 명확

#### 옵션 2: Teacher = Product 포함(또는 reaction SMILES), Student = Reactants-only
- Teacher는 product-side view에서 prototype 분포를 만들고,
- Student는 reactants만으로 그 분포를 복원

> 논문 임팩트 관점에서 가장 깔끔한 건 **“Δ(변환) view를 Teacher가 갖는 설정”**이다.

---

### 2.3 DINO 학습 설계(핵심)

#### (A) 네트워크 구성
- **Student encoder**: Reactants-only GNN (MPNN/GIN/GAT 중 택1)
  - 입력이 “분자 set”이므로 **set pooling(DeepSets)** 또는 **attention pooling** 권장
- **Teacher encoder**: CGR-GNN(또는 product-side encoder)
  - Teacher는 capacity를 더 크게 잡아도 좋음
- **DINO head**
  - `projector MLP → prototype layer(K개의 프로토타입) → softmax 분포`
  - `EMA teacher 업데이트 + centering/temperature`

#### (B) Multi-view(증강) — “Reaction 전용”으로 설계해야 논문이 됨

**Student view(더 어려운 입력)**
- reactant set에서 일부 molecule drop
  - 단, 반응물 실체가 바뀌면 안 되므로 “drop=mask” 개념으로 안전하게
- atom-feature masking(원자가/전하/방향족 등)
- subgraph crop
  - teacher가 예측한 reaction center 근방만 남기고 나머지 축소 → 반응점 inductive bias

**Teacher view(더 강한/특권 입력)**
- CGR 전체 유지 + 약한 노이즈(마스킹 정도)
- 또는 product 포함/조건 포함(가능할 때)

#### (C) Loss 패키지(논문형)
기본은 DINO cross-entropy(teacher 분포를 student가 맞춤). 그 위에 1~2개 “화학적 보조 손실”을 얹으면 임팩트가 커진다.
- (추가1) **Reaction center prediction**: student embedding으로 “변하는 bond/atom” 예측(teacher의 Δ에서 pseudo-label 생성)
- (추가2) **Bond-change type classification**: 형성/절단/차수변화 등 변환 타입 예측
- (추가3) **Contrastive alignment(선택)**: 동일 반응의 다른 표기/순서에 invariant하도록

---

### 2.4 학습 루프(엔지니어링 포인트)
- **데이터 로더**: 반응 그래프 생성 비용이 크므로 **전처리 캐시(parquet + pickle/npz)** 필수
- **학습 안정화**
  - prototype 수 K, temperature, centering momentum은 성능에 민감
  - collapse 모니터링(프로토타입 사용률 entropy)
- **체크포인트**
  - best-by-validation + periodic save
- **Mixed precision / gradient accumulation**
  - 대규모 pretrain에 필수

---

## 3. 다운스트림 태스크 설계(임팩트가 터지는 평가)

Reaction DINO는 “반응 예측 모델” 자체보다, **반응 representation backbone**으로 임팩트를 내는 쪽이 논문 완성도가 높다.

### 3.1 필수 다운스트림 3종 세트(권장)
1. **Reaction classification**
2. **Reaction retrieval / clustering** (반응 검색 = 실전 가치 큼)
3. **Yield prediction(가능하면)** 또는 조건 예측

#### 베이스라인 비교
- **rxnfp**: learned reaction fingerprint 대표
- **DRFP**: 강력한 non-learned baseline
- **CGR learned reps**: 반응 특성 예측에 강점

### 3.2 (선택) Forward/Retro 예측에 연결하는 방식
- embedding을 transformer forward model에 **prefix/adapter**로 붙여 성능 향상(특히 low-data split에서)
- 또는 retrieval-augmented: 유사 반응 top-k 검색 → 조건/생성물 후보 rerank

---

## 4. 실험 설계(논문 완성도를 좌우하는 ablation)

최소 이 6개는 무조건 돌리는 것을 추천:
1. Teacher input: `product vs CGR(Δ) vs (product+conditions)`
2. Student input: `reactants-only vs reactants+reagents`
3. DINO head 유무: `plain distill vs prototype`
4. Multi-view 유무(특히 reaction-center crop)
5. Atom-mapping 의존성: teacher만 mapping 필요하게 만들 수 있나?
6. Split robustness: `random vs scaffold/tanimoto/temporal`

---

## 5. 구현 파이프라인(폴더 구조 + 실행 흐름)

### 5.1 추천 디렉토리 구조
```text
reaction-dino/
  configs/                 # hydra yaml
  data_raw/                # 원본 (다운로드/변환 전)
  data_proc/               # 정제/토큰/그래프 캐시 (parquet/npz)
  src/
    data/
      standardize.py       # RDKit 표준화
      atom_mapping.py      # mapping 생성/검증(옵션)
      build_cgr.py         # CGR 생성
      featurize_graph.py   # PyG graph 저장
      splits.py            # random/scaffold/tanimoto/temporal
    models/
      enc_student.py       # reactants-only GNN + set pooling
      enc_teacher.py       # CGR-GNN or product encoder
      dino_head.py         # projector + prototypes + centering
      ema.py               # EMA update
    train/
      pretrain_reaction_dino.py
      finetune_classifier.py
      finetune_yield.py
      eval_retrieval.py
    utils/
      logging_utils.py     # logging + file handler
      metrics.py
      ckpt.py
  runs/                    # 실험 결과(자동 생성)
  notebooks/               # 분석용
  README.md
```

### 5.2 “원클릭” 실행 순서(권장)

1. `standardize.py` → 정규화 + dedup
2. `atom_mapping.py`(teacher용) → mapping 품질 검사
3. `build_cgr.py` → CGR 생성
4. `featurize_graph.py` → PyG 캐시
5. `splits.py` → split 생성(여러 버전)
6. `pretrain_reaction_dino.py` → self-distillation pretrain
7. `finetune_* + eval_*` → 다운스트림 평가
8. `notebooks/` → ablation plot + table 자동 생성

---

## 6. 로깅/재현성(“최선의 결과물”에 필수)

### 모든 스크립트는

* `logging`으로 **파일 + 콘솔** 동시 기록
* 데이터/스플릿 버전, git commit hash, seed, config dump 저장
* epoch/batch 진행률은 `tqdm`

### 실험 결과는

* metrics: `csv + json + (가능하면 wandb)`
* confusion matrix / retrieval tmap plot(선택)

### 데이터는

* 처리 단계별 hash 저장(“이 결과가 어떤 데이터에서 나왔는지”)

---

## 7. “논문 임팩트”를 만드는 최종 산출물 패키지

최종적으로 아래 5개가 있으면 거의 논문 패키지 완성:

1. Reaction DINO 프레임워크(Teacher privileged info → Student minimal info)
2. 벤치마크 3종(분류/검색/수율)에서 SOTA 또는 strong baseline 대비 유의미한 향상
3. split robustness(특히 scaffold/tanimoto/temporal)에서 유지
4. ablation으로 “왜 되는지” 설명(Δ-view, center crop, mapping 의존성 제거)
5. 실제 활용 시나리오(retrieval-augmented synthesis planning 등) 데모

---

## 바로 다음 액션(가장 효율적인 MVP)

1. `Teacher = CGR`, `Student = reactants-only`로 고정
2. 사전학습: `USPTO-MIT/FULL`, 평가: `USPTO-50K`
3. 다운스트림: `reaction classification + retrieval(반드시) + (가능하면) yield`
4. baseline: `rxnfp + DRFP + CGR-learned`

---
