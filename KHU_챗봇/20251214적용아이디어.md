응, KHU 규정집(혹은 학사/행정 문서) 기반 챗봇에도 그대로 적용 가능해. 오히려 “환각 방지 + 근거 기반 답변”이 핵심인 도메인이라 체감 효과가 큰 편이야.

KHU 챗봇에 적용했을 때 바뀌는 핵심

1. 문서 파싱(ingestion) 강화


기존: PDF → 텍스트만 뽑아서 chunk

적용: PDF/Word → 구조화(예: Markdown) → heading 기반 chunk
→ “제n조 / 제m항 / 부칙 / 별표 / 표” 같은 구조가 살아서 검색 정확도가 보통 올라감


2. Relevance Gate(관련성 게이트) 추가


질문이 규정집 범위 밖이면 바로
“제공된 규정 문서로는 답할 수 없음”
→ 규정 챗봇에서 가장 중요한 환각 방지 장치


3. Hybrid Retrieval(BM25 + Embedding)


규정 문서/법령 스타일은 **키워드 매칭(BM25)**이 강하고,

질문이 우회 표현이면 임베딩이 강함
→ 둘을 섞으면 안정적으로 올라감


4. Verification Gate(검증 에이전트) + 자기수정 루프


답변 생성 후 “근거 문장/조항이 실제로 있는지” 확인

근거가 약하면: 재검색(top-k 확대, BM25 가중↑ 등) → 재답변
→ 최종적으로 “근거 있는 답만” 나가게 만들 수 있음


---

네 KHU 챗봇에 끼워 넣는 위치(실전 적용 순서)

(A) 문서 업로드/인덱싱 단계

Docling(또는 네가 쓰는 파서)로 Markdown 변환

heading split + 캐싱 + 중복 제거


(B) 질문 처리 단계

1. Retrieve(top-k)


2. RelevanceChecker로 CAN_ANSWER/PARTIAL/NO_MATCH


3. NO_MATCH면 종료(거절)


4. ResearchAgent로 답변 생성


5. VerificationAgent로 “근거/모순/무관” 체크


6. 실패하면 루프(최대 N회) 후, 그래도 안 되면 “문서 근거 부족”으로 종료


---

적용용 “파이프라인 뼈대 코드” (logging + tqdm 포함)

아래는 네 KHU RAG 앱(예: Streamlit/FastAPI + LangChain)에 바로 붙이기 좋은 형태야.
코드는 번역/변형 최소화했고, 핵심은 “게이트+검증+루프” 구조야.

import logging
from logging.handlers import RotatingFileHandler
from dataclasses import dataclass
from typing import List, Dict, Any, Optional
from tqdm import tqdm

# ===== logging setup =====
def setup_logger(name: str = "khu_rag", log_path: str = "khu_rag.log") -> logging.Logger:
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    if not logger.handlers:
        fmt = logging.Formatter("%(asctime)s [%(levelname)s] %(name)s - %(message)s")
        fh = RotatingFileHandler(log_path, maxBytes=5_000_000, backupCount=3, encoding="utf-8")
        fh.setFormatter(fmt)
        sh = logging.StreamHandler()
        sh.setFormatter(fmt)
        logger.addHandler(fh)
        logger.addHandler(sh)
    return logger

logger = setup_logger()

# ====== contracts ======
@dataclass
class QAResult:
    answer: str
    used_context: str
    relevance: str
    verification_report: str
    iterations: int

# ====== core pipeline ======
class AgenticRAGPipeline:
    """
    Plug-in points:
      - retriever: must have invoke(question)->List[Document]
      - relevance_checker: has check(question, retriever, k)->label
      - research_agent: has generate(question, documents)->{"draft_answer","context_used"}
      - verification_agent: has check(answer, documents)->{"verification_report","context_used"}
    """
    def __init__(
        self,
        retriever,
        relevance_checker,
        research_agent,
        verification_agent,
        k: int = 4,
        max_iters: int = 2,
    ):
        self.retriever = retriever
        self.relevance_checker = relevance_checker
        self.research_agent = research_agent
        self.verification_agent = verification_agent
        self.k = k
        self.max_iters = max_iters

    def run(self, question: str) -> QAResult:
        logger.info(f"[Q] {question}")

        # 1) relevance gate
        relevance = self.relevance_checker.check(question, self.retriever, k=self.k)
        logger.info(f"[Relevance] {relevance}")

        if relevance == "NO_MATCH":
            msg = "제공된 규정/문서 범위에서 이 질문을 뒷받침할 근거를 찾지 못했습니다."
            logger.info("[Stop] NO_MATCH -> refuse")
            return QAResult(
                answer=msg,
                used_context="",
                relevance=relevance,
                verification_report="",
                iterations=0,
            )

        # 2) self-correction loop (retrieve -> answer -> verify)
        last_answer = ""
        last_context = ""
        last_report = ""
        iters = 0

        for iters in tqdm(range(1, self.max_iters + 1), desc="self-correct"):
            docs = self.retriever.invoke(question)[: self.k * iters]  # widen context each iter
            logger.info(f"[Retrieve] iter={iters}, docs={len(docs)}")

            # generate
            gen = self.research_agent.generate(question, docs)
            last_answer = gen["draft_answer"]
            last_context = gen["context_used"]
            logger.info(f"[DraftAnswer] iter={iters}, len={len(last_answer)}")

            # verify
            ver = self.verification_agent.check(last_answer, docs)
            last_report = ver["verification_report"]
            logger.info(f"[VerifyReport] iter={iters}\n{last_report}")

            # very simple pass/fail heuristic (you can make this stricter)
            # Expect lines like: "Supported: YES" and "Relevant: YES"
            report_upper = last_report.upper()
            if ("SUPPORTED: YES" in report_upper) and ("RELEVANT: YES" in report_upper) and ("CONTRADICTIONS:" in report_upper):
                logger.info(f"[PASS] iter={iters}")
                break
            logger.info(f"[FAIL] iter={iters} -> retry with wider retrieval")

        return QAResult(
            answer=last_answer,
            used_context=last_context,
            relevance=relevance,
            verification_report=last_report,
            iterations=iters,
        )

이 코드에서 네 KHU 챗봇에 “구체적으로 연결”하면?

너의 기존 retriever(벡터DB/FAISS/LanceDB/Chroma 등)를 그대로 넣고,

RelevanceChecker, ResearchAgent, VerificationAgent는 네가 붙여준 것과 동일 컨셉으로 연결하면 끝.


---

기대 효과 (KHU 규정 챗봇 관점)

“없는 규정 조항을 만들어내는” 답변이 현저히 줄어듦

**근거(조항/항/별표)**가 붙은 답변으로 수렴

질문이 애매하거나 범위 밖이면 “모른다/근거 부족”으로 안전하게 종료


---

주의할 점 3가지 (실전에서 자주 터짐)

1. 검증 프롬프트가 느슨하면 “Supported: YES” 남발함
→ 검증 에이전트 프롬프트를 “근거 문장/조항을 인용하라(quote)” 쪽으로 강화하는 게 좋음


2. BM25 토크나이저
규정/한국어는 형태소 쪽이 유리한데, 최소한 “조/항/호/별표/부칙” 같은 키워드는 tokenizer/전처리로 살리는 게 도움 됨


3. 문서 버전 관리 규정 개정이 잦으면 “어느 날짜/버전 규정인지” 메타데이터를 chunk에 붙이고, 답변에 버전도 같이 출력하는 게 안전함


---

원하면, 네 KHU 챗봇의 현재 구조(예: 어떤 벡터DB/리트리버, chunk 전략, UI가 Streamlit인지 등)를 내가 임의로 표준 형태로 가정해서, “Docling 파서 + 하이브리드 리트리버 + 위 파이프라인”까지 한 번에 붙는 완성형 폴더 구조/코드로도 정리해줄게.
